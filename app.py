import streamlit as st
import cv2
import numpy as np
import pandas as pd

def process_tomatoes(image_file, min_area, h_min, s_min, v_min, separation_strength):
    # ç”»åƒèª­ã¿è¾¼ã¿
    file_bytes = np.asarray(bytearray(image_file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)
    
    # ãƒã‚¤ã‚ºé™¤å»ï¼ˆãƒ–ãƒ©ãƒ¼ï¼‰
    blurred = cv2.GaussianBlur(img, (5, 5), 0)
    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

    # 1. è‰²ã«ã‚ˆã‚‹æŠ½å‡ºï¼ˆå‰å›ã¨åŒã˜ï¼‰
    lower_red1 = np.array([0, s_min, v_min])
    upper_red1 = np.array([h_min, 255, 255])
    lower_red2 = np.array([180 - h_min, s_min, v_min])
    upper_red2 = np.array([180, 255, 255])

    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask = mask1 + mask2

    # ãƒã‚¤ã‚ºå‡¦ç†ï¼ˆç©´åŸ‹ã‚ï¼‰
    kernel = np.ones((3,3), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)
    # è†¨å¼µã•ã›ã™ãã‚‹ã¨ãã£ã¤ãã®ã§ã€ã“ã“ã¯æ§ãˆã‚ã«
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)

    # --- ã“ã“ã‹ã‚‰æ–°ã—ã„åˆ†é›¢ãƒ­ã‚¸ãƒƒã‚¯ (Watershed) ---
    
    # èƒŒæ™¯ã‚’ç¢ºå®Ÿã«ã™ã‚‹ï¼ˆè†¨å¼µï¼‰
    sure_bg = cv2.dilate(mask, kernel, iterations=3)

    # å‰æ™¯ï¼ˆãƒˆãƒãƒˆã®ä¸­å¿ƒï¼‰ã‚’ç¢ºå®Ÿã«ã™ã‚‹ï¼ˆè·é›¢å¤‰æ›ï¼‰
    dist_transform = cv2.distanceTransform(mask, cv2.DIST_L2, 5)
    
    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§åˆ†é›¢å¼·åº¦ã‚’èª¿æ•´
    # separation_strength ã¯ 0.0 ~ 1.0ã€‚é«˜ã„ã»ã©ä¸­å¿ƒã ã‘ã‚’å³å¯†ã«å–ã‚‹ï¼ˆåˆ†é›¢ã—ã‚„ã™ããªã‚‹ï¼‰
    ret, sure_fg = cv2.threshold(dist_transform, separation_strength * dist_transform.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)

    # ä¸æ˜é ˜åŸŸï¼ˆå¢ƒç•Œç·šå€™è£œï¼‰
    unknown = cv2.subtract(sure_bg, sure_fg)

    # ãƒãƒ¼ã‚«ãƒ¼ä½œæˆ
    ret, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1 # èƒŒæ™¯ã‚’1ã«ã™ã‚‹
    markers[unknown == 255] = 0 # ä¸æ˜é ˜åŸŸã‚’0ã«ã™ã‚‹

    # Watershedå®Ÿè¡Œ
    markers = cv2.watershed(img, markers)
    
    # å¢ƒç•Œç·šã‚’æç”»ï¼ˆé»„è‰²ï¼‰
    img[markers == -1] = [0, 255, 255]

    # è§£æçµæœã®åé›†
    results = []
    img_out = img.copy()
    
    # ãƒãƒ¼ã‚«ãƒ¼ã”ã¨ã«ãƒ«ãƒ¼ãƒ—ï¼ˆãƒ©ãƒ™ãƒ«1ã¯èƒŒæ™¯ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    unique_markers = np.unique(markers)
    obj_count = 0

    for marker_id in unique_markers:
        if marker_id <= 1: # èƒŒæ™¯ã¾ãŸã¯å¢ƒç•Œç·š
            continue

        # ã“ã®ãƒãƒ¼ã‚«ãƒ¼ã®ãƒã‚¹ã‚¯ã‚’ä½œæˆ
        obj_mask = np.zeros_like(mask, dtype=np.uint8)
        obj_mask[markers == marker_id] = 255

        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(obj_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < min_area:
                continue
            
            obj_count += 1
            
            # æ¥•å††ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
            if len(cnt) >= 5:
                ellipse = cv2.fitEllipse(cnt)
                cv2.ellipse(img_out, ellipse, (0, 255, 0), 2)
                
                axis_lengths = ellipse[1]
                long_axis = max(axis_lengths)
                short_axis = min(axis_lengths)
                
                ratio = short_axis / long_axis
                ratio_text = f"1:{ratio:.2f}"
                
                results.append({
                    "ID": obj_count,
                    "é•·è»¸(px)": round(long_axis, 1),
                    "çŸ­è»¸(px)": round(short_axis, 1),
                    "ç¸¦:æ¨ª": ratio_text
                })

                # ãƒ†ã‚­ã‚¹ãƒˆæç”»
                M = cv2.moments(cnt)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    cv2.putText(img_out, str(obj_count), (cX - 10, cY), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    # ãƒ¢ãƒ‹ã‚¿ãƒ¼ç”¨ã«è·é›¢å¤‰æ›ç”»åƒã‚’å¯è¦–åŒ–
    dist_display = cv2.normalize(dist_transform, None, 0, 255, cv2.NORM_MINMAX)
    dist_display = np.uint8(dist_display)
    dist_display = cv2.cvtColor(dist_display, cv2.COLOR_GRAY2BGR)

    return img_out, dist_display, results

# --- Streamlit UI ---

st.title("ğŸ… ãƒˆãƒãƒˆå½¢çŠ¶è§£æãƒ„ãƒ¼ãƒ« (åˆ†é›¢æ©Ÿèƒ½ä»˜ã)")

st.sidebar.header("1. æ¤œå‡ºæ„Ÿåº¦ & åˆ†é›¢")

# ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
st.sidebar.subheader("åŸºæœ¬æ¤œå‡º")
s_min = st.sidebar.slider("å½©åº¦(S) ä¸‹é™", 0, 255, 60)
v_min = st.sidebar.slider("æ˜ã‚‹ã•(V) ä¸‹é™", 0, 255, 60)
h_min = st.sidebar.slider("è‰²ç›¸(H) å¹…", 1, 30, 8)
min_area = st.sidebar.slider("æœ€å°ã‚µã‚¤ã‚ºé™¤å»", 0, 5000, 200)

st.sidebar.subheader("ãã£ã¤ãåˆ†é›¢")
separation_strength = st.sidebar.slider("åˆ†é›¢å¼·åº¦", 0.1, 0.9, 0.5, 0.05, help="å€¤ã‚’ä¸Šã’ã‚‹ã¨ã€ãã£ã¤ã„ãŸãƒˆãƒãƒˆã‚’å¼·ãåˆ‡ã‚Šé›¢ãã†ã¨ã—ã¾ã™ã€‚ä¸Šã’ã™ãã‚‹ã¨ãƒˆãƒãƒˆãŒæ¶ˆãˆã¾ã™ã€‚")

uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    processed_img, dist_img, data = process_tomatoes(uploaded_file, min_area, h_min, s_min, v_min, separation_strength)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("æ¤œå‡ºçµæœ")
        st.image(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB), use_container_width=True)

    with col2:
        st.subheader("åˆ†é›¢åˆ¤å®šç”¨ãƒ¢ãƒ‹ã‚¿ãƒ¼")
        st.markdown("ãƒˆãƒãƒˆã®ã€ŒèŠ¯ï¼ˆä¸­å¿ƒï¼‰ã€ãŒæ˜ã‚‹ãå…‰ã‚Šã¾ã™ã€‚ã“ã“ãŒé›¢ã‚Œã¦ã„ã‚Œã°åˆ†é›¢ã§ãã¾ã™ã€‚")
        st.image(dist_img, caption="è·é›¢å¤‰æ›ç”»åƒ", use_container_width=True)

    st.subheader("è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿")
    if data:
        df = pd.DataFrame(data)
        st.dataframe(df)
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name='tomato_v3.csv', mime='text/csv')
    else:
        st.warning("ãƒˆãƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
